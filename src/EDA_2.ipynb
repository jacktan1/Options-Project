{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering (Continued from `EDA_1`)\n",
    "**Import required packages & check working directory**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from EDA_fun_graph import ts_decompose\n",
    "from EDA_fun_multithread import fit_linear_model, kendall_rank\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import time\n",
    "\n",
    "if os.getcwd()[-3:] == \"src\":\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**User defined parameters**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "options_path = f\"data/EDA1/{ticker}\"\n",
    "adj_daily_closing_path = \"data/adjusted_daily_closing/\"\n",
    "dividends_path = \"data/dividends/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Bookkeeping variables\n",
    "COMPLETE_DICT = dict()\n",
    "INCOMPLETE_DICT = dict()\n",
    "\n",
    "for year in os.listdir(options_path):\n",
    "    for file in os.listdir(os.path.join(options_path, year)):\n",
    "        # Load\n",
    "        temp_df = pd.read_csv(os.path.join(os.path.join(options_path, year, file)))\n",
    "\n",
    "        # Convert columns to correct format\n",
    "        temp_df[\"date\"] = pd.to_datetime(temp_df[\"date\"]).dt.date\n",
    "        temp_df[\"expiration date\"] = pd.to_datetime(temp_df[\"expiration date\"]).dt.date\n",
    "\n",
    "        if file.split(\"_\")[-1] == \"complete.csv\":\n",
    "            COMPLETE_DICT[year] = temp_df\n",
    "        elif file.split(\"_\")[-1] == \"incomplete.csv\":\n",
    "            INCOMPLETE_DICT[year] = temp_df\n",
    "        else:\n",
    "            raise Exception(\"No other type of file should exist!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "date_close_df = pd.read_csv(os.path.abspath(os.path.join(adj_daily_closing_path, (ticker + \".csv\"))))\n",
    "date_close_df[\"date\"] = pd.to_datetime(date_close_df[\"date\"]).dt.date\n",
    "\n",
    "dividends_df = pd.read_csv(os.path.abspath(os.path.join(dividends_path, (ticker + \"_ts.csv\"))))\n",
    "dividends_df[\"date\"] = pd.to_datetime(dividends_df[\"date\"]).dt.date\n",
    "\n",
    "date_close_df = date_close_df[[\"date\", \"close\"]].merge(right=dividends_df,\n",
    "                                                       how=\"inner\", on=\"date\")\n",
    "\n",
    "date_close_df[\"adj close\"] = (date_close_df[\"close\"] - date_close_df[\"dividend\"]).round(6)\n",
    "date_close_df = date_close_df[[\"date\", \"adj close\"]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cells below to explore methods of preprocessing\n",
    "\n",
    "Dickey-Fuller test on adjusted close price (segmented annually)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "    year  ADF statistic   p-value\n0   2005       0.252304  0.975047\n1   2006      -0.991645  0.756299\n2   2007       0.423419  0.982350\n3   2008      -0.945886  0.772486\n4   2009      -0.567357  0.878189\n5   2010      -0.522971  0.887455\n6   2011      -1.769742  0.395584\n7   2012      -2.396842  0.142630\n8   2013      -0.728815  0.839144\n9   2014      -0.447082  0.901936\n10  2015      -1.821966  0.369612\n11  2016      -1.389640  0.587233\n12  2017      -1.980752  0.295076\n13  2018      -0.981442  0.759973\n14  2019       0.630881  0.988353\n15  2020      -0.146467  0.944609\n16  2021      -0.017002  0.957103",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>ADF statistic</th>\n      <th>p-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2005</td>\n      <td>0.252304</td>\n      <td>0.975047</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2006</td>\n      <td>-0.991645</td>\n      <td>0.756299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007</td>\n      <td>0.423419</td>\n      <td>0.982350</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008</td>\n      <td>-0.945886</td>\n      <td>0.772486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009</td>\n      <td>-0.567357</td>\n      <td>0.878189</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2010</td>\n      <td>-0.522971</td>\n      <td>0.887455</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011</td>\n      <td>-1.769742</td>\n      <td>0.395584</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2012</td>\n      <td>-2.396842</td>\n      <td>0.142630</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2013</td>\n      <td>-0.728815</td>\n      <td>0.839144</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2014</td>\n      <td>-0.447082</td>\n      <td>0.901936</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2015</td>\n      <td>-1.821966</td>\n      <td>0.369612</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2016</td>\n      <td>-1.389640</td>\n      <td>0.587233</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2017</td>\n      <td>-1.980752</td>\n      <td>0.295076</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2018</td>\n      <td>-0.981442</td>\n      <td>0.759973</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2019</td>\n      <td>0.630881</td>\n      <td>0.988353</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2020</td>\n      <td>-0.146467</td>\n      <td>0.944609</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2021</td>\n      <td>-0.017002</td>\n      <td>0.957103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickey_df = pd.DataFrame(columns=[\"year\", \"ADF statistic\", \"p-value\"])\n",
    "\n",
    "min_year = 2005\n",
    "max_year = 2021\n",
    "\n",
    "for n in range(min_year, max_year + 1):\n",
    "    year_df = date_close_df[pd.to_datetime(date_close_df[\"date\"]).dt.year == n]\n",
    "    adf_year = adfuller(year_df[\"adj close\"], regression=\"c\", autolag=\"AIC\")\n",
    "    dickey_df = dickey_df.append({\"year\": n, \"ADF statistic\": adf_year[0], \"p-value\": adf_year[1]}, ignore_index=True)\n",
    "\n",
    "dickey_df[\"year\"] = dickey_df[\"year\"].astype(int)\n",
    "\n",
    "dickey_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since for most/all years, the p-value is greater than 0.05, we cannot reject the null hypothesis that a unit root is present.\n",
    "\n",
    "Graph of time series, autocorrelation (ACF) and partial ACF of entire ticker history to pick appropriate de-trending options."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "acf_df = date_close_df.copy()\n",
    "\n",
    "acf_lags = []\n",
    "\n",
    "# Close dates, do not include 0\n",
    "acf_lags.extend(np.arange(1, 6))\n",
    "\n",
    "# Month\n",
    "acf_lags.extend(np.arange(15, 26))\n",
    "\n",
    "# Quarter\n",
    "acf_lags.extend(np.arange(75, 96))\n",
    "\n",
    "# Year\n",
    "acf_lags.extend(np.arange(240, 266))\n",
    "\n",
    "acf_plot = ts_decompose(ts_df=acf_df, min_year=min_year, max_year=max_year,\n",
    "                        lags=acf_lags, pacf_lag=10)\n",
    "\n",
    "acf_plot.write_image(\"./img/EDA2_ACF.svg\", width=1000, height=800)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF.svg)\n",
    "\n",
    "First take a differencing of 1 day as it is the overarching signal here, then re-examine for finer seasonality."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "acf_df[f\"delta {n}\"] = acf_df[\"adj close\"].shift(periods=-n) - acf_df[\"adj close\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Price change n days into the future\n",
    "n = 1\n",
    "\n",
    "acf_df[f\"delta {n}\"] = acf_df[\"adj close\"].shift(periods=-n) - acf_df[\"adj close\"]\n",
    "\n",
    "acf_plot2 = ts_decompose(ts_df=acf_df[[\"date\", f\"delta {n}\"]], min_year=min_year, max_year=max_year,\n",
    "                         lags=acf_lags, pacf_lag=10)\n",
    "\n",
    "acf_plot2.write_image(\"./img/EDA2_ACF2.svg\", width=1000, height=800)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF2.svg)\n",
    "\n",
    "Need to normalize (variance increases as underlying ticker price also increases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "acf_df[f\"delta {n} norm\"] = acf_df[f\"delta {n}\"] / acf_df[\"adj close\"].shift(periods=n)\n",
    "\n",
    "acf_plot3 = ts_decompose(ts_df=acf_df[[\"date\", f\"delta {n} norm\"]], min_year=min_year, max_year=max_year,\n",
    "                         lags=acf_lags, pacf_lag=10)\n",
    "\n",
    "acf_plot3.write_image(\"./img/EDA2_ACF3.svg\", width=1000, height=800)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF3.svg)\n",
    "\n",
    "This residual is stationary, and has expected characteristics (greater volatility in 2008 and beginning of 2020).\n",
    "\n",
    "With this detrending method, we calculate the stationary dependent variable for various lags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "acf_plot3.show(renderer=\"browser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Target (*Y*) Variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "my_lags = [1, 2, 5, 10, 15, 20, 40, 60, 120, 180, 252]\n",
    "min_year = 2005\n",
    "max_year = 2021\n",
    "\n",
    "Y_LAGS_STAT = date_close_df.copy()\n",
    "\n",
    "for n in my_lags:\n",
    "    Y_LAGS_STAT[str(n)] = (Y_LAGS_STAT[\"adj close\"].shift(periods=-n) - Y_LAGS_STAT[\"adj close\"]) / Y_LAGS_STAT[\n",
    "        \"adj close\"].shift(periods=n)\n",
    "\n",
    "Y_LAGS_STAT = Y_LAGS_STAT[(pd.to_datetime(Y_LAGS_STAT[\"date\"]).dt.year >= min_year) &\n",
    "                          (pd.to_datetime(Y_LAGS_STAT[\"date\"]).dt.year <= max_year)]\n",
    "\n",
    "Y_LAGS_STAT.drop(columns=\"adj close\", inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use Dickey-Fuller test to examine stationarity at different lags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                       lag 1     lag 2    lag 5   lag 10   lag 15   lag 20  \\\nADF Stat.          -15.36720 -10.85631 -9.90605 -9.12094 -8.17547 -9.01673   \np-value              0.00000   0.00000  0.00000  0.00000  0.00000  0.00000   \ncritical value 1%   -3.43188  -3.43189 -3.43189 -3.43189 -3.43189 -3.43189   \ncritical value 5%   -2.86222  -2.86222 -2.86222 -2.86222 -2.86222 -2.86222   \ncritical value 10%  -2.56713  -2.56713 -2.56713 -2.56713 -2.56713 -2.56713   \n\n                     lag 40   lag 60  lag 120  lag 180  lag 252  \nADF Stat.          -9.22906 -6.56879 -4.88917 -4.18588 -3.89412  \np-value             0.00000  0.00000  0.00004  0.00070  0.00208  \ncritical value 1%  -3.43190 -3.43190 -3.43193 -3.43195 -3.43198  \ncritical value 5%  -2.86222 -2.86223 -2.86224 -2.86225 -2.86226  \ncritical value 10% -2.56713 -2.56714 -2.56714 -2.56715 -2.56715  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lag 1</th>\n      <th>lag 2</th>\n      <th>lag 5</th>\n      <th>lag 10</th>\n      <th>lag 15</th>\n      <th>lag 20</th>\n      <th>lag 40</th>\n      <th>lag 60</th>\n      <th>lag 120</th>\n      <th>lag 180</th>\n      <th>lag 252</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ADF Stat.</th>\n      <td>-15.36720</td>\n      <td>-10.85631</td>\n      <td>-9.90605</td>\n      <td>-9.12094</td>\n      <td>-8.17547</td>\n      <td>-9.01673</td>\n      <td>-9.22906</td>\n      <td>-6.56879</td>\n      <td>-4.88917</td>\n      <td>-4.18588</td>\n      <td>-3.89412</td>\n    </tr>\n    <tr>\n      <th>p-value</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00004</td>\n      <td>0.00070</td>\n      <td>0.00208</td>\n    </tr>\n    <tr>\n      <th>critical value 1%</th>\n      <td>-3.43188</td>\n      <td>-3.43189</td>\n      <td>-3.43189</td>\n      <td>-3.43189</td>\n      <td>-3.43189</td>\n      <td>-3.43189</td>\n      <td>-3.43190</td>\n      <td>-3.43190</td>\n      <td>-3.43193</td>\n      <td>-3.43195</td>\n      <td>-3.43198</td>\n    </tr>\n    <tr>\n      <th>critical value 5%</th>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86222</td>\n      <td>-2.86223</td>\n      <td>-2.86224</td>\n      <td>-2.86225</td>\n      <td>-2.86226</td>\n    </tr>\n    <tr>\n      <th>critical value 10%</th>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56713</td>\n      <td>-2.56714</td>\n      <td>-2.56714</td>\n      <td>-2.56715</td>\n      <td>-2.56715</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adfuller_df = pd.DataFrame(index=[\"ADF Stat.\", \"p-value\",\n",
    "                                  \"critical value 1%\", \"critical value 5%\", \"critical value 10%\"])\n",
    "\n",
    "for n in my_lags:\n",
    "    temp_adfuller = adfuller(Y_LAGS_STAT[str(n)].dropna(), regression=\"c\", autolag=\"AIC\")\n",
    "\n",
    "    adfuller_df[f\"lag {n}\"] = [round(temp_adfuller[0], 5),\n",
    "                               round(temp_adfuller[1], 5),\n",
    "                               round(temp_adfuller[4][\"1%\"], 5),\n",
    "                               round(temp_adfuller[4][\"5%\"], 5),\n",
    "                               round(temp_adfuller[4][\"10%\"], 5)]\n",
    "\n",
    "adfuller_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The further away from lag = 1, the less the dependent variable (lag n) remains stationary. Individual years may be non-stationary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    year  ADF statistic       p-value\n0   2005     -15.738123  1.265472e-28\n1   2006     -15.627311  1.702459e-28\n2   2007     -12.222780  1.097625e-22\n3   2008     -12.570767  2.006525e-23\n4   2009     -11.630881  2.264155e-21\n5   2010     -15.381526  3.402503e-28\n6   2011      -9.293361  1.163628e-15\n7   2012     -15.668640  1.522426e-28\n8   2013      -6.142854  7.894461e-08\n9   2014     -15.365245  3.568136e-28\n10  2015     -16.141311  4.672813e-29\n11  2016     -11.046115  5.218144e-20\n12  2017      -6.326448  2.978284e-08\n13  2018     -15.005432  1.074512e-27\n14  2019     -12.421873  4.119758e-23\n15  2020      -4.865843  4.062551e-05\n16  2021     -16.254603  3.616703e-29",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>ADF statistic</th>\n      <th>p-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2005</td>\n      <td>-15.738123</td>\n      <td>1.265472e-28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2006</td>\n      <td>-15.627311</td>\n      <td>1.702459e-28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007</td>\n      <td>-12.222780</td>\n      <td>1.097625e-22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008</td>\n      <td>-12.570767</td>\n      <td>2.006525e-23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009</td>\n      <td>-11.630881</td>\n      <td>2.264155e-21</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2010</td>\n      <td>-15.381526</td>\n      <td>3.402503e-28</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011</td>\n      <td>-9.293361</td>\n      <td>1.163628e-15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2012</td>\n      <td>-15.668640</td>\n      <td>1.522426e-28</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2013</td>\n      <td>-6.142854</td>\n      <td>7.894461e-08</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2014</td>\n      <td>-15.365245</td>\n      <td>3.568136e-28</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2015</td>\n      <td>-16.141311</td>\n      <td>4.672813e-29</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2016</td>\n      <td>-11.046115</td>\n      <td>5.218144e-20</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2017</td>\n      <td>-6.326448</td>\n      <td>2.978284e-08</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2018</td>\n      <td>-15.005432</td>\n      <td>1.074512e-27</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2019</td>\n      <td>-12.421873</td>\n      <td>4.119758e-23</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2020</td>\n      <td>-4.865843</td>\n      <td>4.062551e-05</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2021</td>\n      <td>-16.254603</td>\n      <td>3.616703e-29</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lag = \"1\"\n",
    "dickey_df = pd.DataFrame(columns=[\"year\", \"ADF statistic\", \"p-value\"])\n",
    "\n",
    "for n in range(min_year, max_year + 1):\n",
    "    # Filter by year\n",
    "    year_df = Y_LAGS_STAT[pd.to_datetime(Y_LAGS_STAT[\"date\"]).dt.year == n]\n",
    "    # Get stats\n",
    "    if not year_df.empty:\n",
    "        adf_year = adfuller(year_df[test_lag].dropna(), regression=\"c\", autolag=\"AIC\")\n",
    "        dickey_df = dickey_df.append({\"year\": n, \"ADF statistic\": adf_year[0], \"p-value\": adf_year[1]},\n",
    "                                     ignore_index=True)\n",
    "\n",
    "dickey_df[\"year\"] = dickey_df[\"year\"].astype(int)\n",
    "\n",
    "dickey_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "acf_plot4 = ts_decompose(ts_df=Y_LAGS_STAT[[\"date\", test_lag]], min_year=min_year, max_year=max_year,\n",
    "                         lags=list(np.arange(1, 252)), pacf_lag=10)\n",
    "\n",
    "acf_plot4.write_image(\"./img/EDA2_ACF4.svg\", width=1000, height=800)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "acf_plot4.show(renderer=\"browser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF4.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit Linear Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit linear regression based on various features\n",
    "1. Baseline linear regression between (days until expiry (DTE) vs. moneyness)\n",
    "2. DTE vs. moneyness * (+/- 1) depending on sign of delta interest / volume\n",
    "3. DTE vs. moneyness * (+/- 1) weighted by delta interest / volume\n",
    "4. DTE vs. moneyness * (+/- 1) weighted by adj. ask price\n",
    "5. DTE vs. moneyness * (+/- 1) weighted by delta interest / volume * ask price\n",
    "\n",
    "**The slope and intercept of these fits are used to characterize daily option \"sentiment\".**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-05-22: No call options with delta interest != 0\n",
      "2006-05-22: No put options with delta interest != 0\n",
      "2006-05-25: No call options with delta interest != 0\n",
      "2006-05-25: No put options with delta interest != 0\n",
      "2006-10-20: No call options with delta interest != 0\n",
      "2006-10-20: No put options with delta interest != 0\n",
      "2008-06-26: No call options with delta interest != 0\n",
      "2008-06-26: No put options with delta interest != 0\n",
      "2008-09-19: No call options with delta interest != 0\n",
      "Fitting approx. 85440 models took 113.784 seconds!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "my_pool = Pool(multiprocessing.cpu_count())\n",
    "\n",
    "# Bookkeeping variables\n",
    "model_types = [\"baseline\", \"sign\", \"tag\", \"price\", \"er\"]\n",
    "LR_RESULTS = {\"delta interest\": {\"call\": {}, \"put\": {}}, \"volume\": {\"call\": {}, \"put\": {}}}\n",
    "input_list = []\n",
    "\n",
    "# Create input list to be processed\n",
    "for year in list(COMPLETE_DICT.keys()):\n",
    "    year_df = COMPLETE_DICT[year]\n",
    "    year_dates = np.unique(year_df[\"date\"])\n",
    "    for date in year_dates:\n",
    "        date_df = year_df[year_df[\"date\"] == date]\n",
    "        for n_1 in [\"delta interest\", \"volume\"]:\n",
    "            for n_2 in [\"call\", \"put\"]:\n",
    "                input_list.append({\"year_df\": COMPLETE_DICT[year], \"date\": date,\n",
    "                                   \"n_1\": n_1, \"n_2\": n_2})\n",
    "\n",
    "results = my_pool.map(fit_linear_model, input_list)\n",
    "\n",
    "for n in results:\n",
    "    # Print output messages\n",
    "    for message in n[\"messages\"]:\n",
    "        print(message)\n",
    "    # Unpack results to desired format\n",
    "    n_1 = n[\"n_1\"]\n",
    "    n_2 = n[\"n_2\"]\n",
    "    for model in model_types:\n",
    "        temp_list = [n[\"date\"]]\n",
    "        temp_list.extend(n[model])\n",
    "        if model not in LR_RESULTS[n_1][n_2].keys():\n",
    "            LR_RESULTS[n_1][n_2][model] = [temp_list]\n",
    "        else:\n",
    "            LR_RESULTS[n_1][n_2][model].append(temp_list)\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "for n_1 in [\"delta interest\", \"volume\"]:\n",
    "    for n_2 in [\"call\", \"put\"]:\n",
    "        for model in model_types:\n",
    "            LR_RESULTS[n_1][n_2][model] = pd.DataFrame(LR_RESULTS[n_1][n_2][model],\n",
    "                                                       columns=[\"date\", \"coef\", \"intercept\"])\n",
    "\n",
    "num_fits = len(input_list) * len(model_types)\n",
    "print(f\"Fitting approx. {num_fits} models took {round(time.time() - start_time, 3)} seconds!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kendall rank correlation of: linear slope / intercept coefficient vs. Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "TAU_RESULTS = {\"delta interest\": {\"call\": {}, \"put\": {}}, \"volume\": {\"call\": {}, \"put\": {}}}\n",
    "\n",
    "for n_1 in [\"delta interest\", \"volume\"]:\n",
    "    for n_2 in [\"call\", \"put\"]:\n",
    "        for n_3 in model_types:\n",
    "            TAU_RESULTS[n_1][n_2][n_3] = dict()\n",
    "            my_years = np.arange(min_year, max_year + 1)\n",
    "            TAU_RESULTS[n_1][n_2][n_3][\"coef\"] = pd.DataFrame(index=my_years, columns=my_lags)\n",
    "            TAU_RESULTS[n_1][n_2][n_3][\"intercept\"] = pd.DataFrame(index=my_years, columns=my_lags)\n",
    "\n",
    "            temp_df1 = LR_RESULTS[n_1][n_2][n_3]\n",
    "            temp_df1 = temp_df1.merge(Y_LAGS_STAT, how=\"left\", on=\"date\", validate=\"1:1\")\n",
    "            temp_df1 = temp_df1\n",
    "\n",
    "            for n_4 in my_years:\n",
    "                temp_df2 = temp_df1[pd.to_datetime(temp_df1[\"date\"]).dt.year == n_4]\n",
    "                for n_5 in my_lags:\n",
    "                    temp_df3 = temp_df2[[\"coef\", \"intercept\", str(n_5)]].dropna()\n",
    "                    if not temp_df3.empty:\n",
    "                        [c_tau, c_pval] = kendalltau(temp_df3[\"coef\"], temp_df3[str(n_5)])\n",
    "                        [i_tau, i_pval] = kendalltau(temp_df3[\"intercept\"], temp_df3[str(n_5)])\n",
    "\n",
    "                        TAU_RESULTS[n_1][n_2][n_3][\"coef\"].loc[n_4, n_5] = round(c_tau, 6)\n",
    "                        TAU_RESULTS[n_1][n_2][n_3][\"intercept\"].loc[n_4, n_5] = round(i_tau, 6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "xaxis=TAU_RESULTS[\"delta interest\"][\"call\"][\"baseline\"][\"coef\"].columns\n",
    "yaxis=TAU_RESULTS[\"delta interest\"][\"call\"][\"baseline\"][\"coef\"].index\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Surface(\n",
    "        x=xaxis,\n",
    "        y=yaxis,\n",
    "        z=np.abs(TAU_RESULTS[\"delta interest\"][\"call\"][\"baseline\"][\"coef\"]), opacity=0.2\n",
    "    ),\n",
    "    # go.Surface(\n",
    "    #     x=xaxis,\n",
    "    #     y=yaxis,\n",
    "    #     z=np.abs(TAU_RESULTS[\"delta interest\"][\"call\"][\"baseline\"][\"intercept\"]), opacity=0.2\n",
    "    # ),\n",
    "    # go.Surface(\n",
    "    #     x=xaxis,\n",
    "    #     y=yaxis,\n",
    "    #     z=np.abs(TAU_RESULTS[\"delta interest\"][\"put\"][\"baseline\"][\"coef\"]), opacity=0.2\n",
    "    # ),\n",
    "    # go.Surface(\n",
    "    #     x=xaxis,\n",
    "    #     y=yaxis,\n",
    "    #     z=np.abs(TAU_RESULTS[\"delta interest\"][\"put\"][\"baseline\"][\"intercept\"]), opacity=0.2\n",
    "    # )\n",
    "])\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "           1         2         5         10        15        20        40   \\\n2005 -0.013912 -0.033574  0.046554  0.091663  0.119357  0.095454  0.131245   \n2006  0.005942 -0.042314 -0.095925 -0.186104 -0.209612 -0.122176 -0.114209   \n2007 -0.049753 -0.070725 -0.094438 -0.133578 -0.096542 -0.070661   0.01259   \n2008 -0.052813 -0.067155 -0.081179 -0.050072 -0.021068 -0.004175  0.175267   \n2009  -0.05369 -0.039461 -0.059318 -0.110921 -0.144375 -0.216278 -0.327895   \n2010  -0.03826 -0.031493 -0.053943 -0.071334  -0.08297 -0.111364   -0.1273   \n2011  0.069942   0.04667  0.016758 -0.105799 -0.173655 -0.171378 -0.245494   \n2012  0.043855   0.03306  0.030747  0.067373  0.071871  0.107984  0.071357   \n2013 -0.021312 -0.035287 -0.034655 -0.012332 -0.003605  0.002403 -0.014482   \n2014  0.060462   0.06588 -0.008382 -0.019793 -0.063203  -0.09839 -0.209625   \n2015  0.058054  0.061405  0.092519  0.108392  0.109657  0.088851  0.090875   \n2016 -0.075824 -0.101436 -0.105989 -0.183963 -0.185607  -0.19446 -0.107886   \n2017  0.024382  0.035729  0.101195  0.074486  0.117578  0.103618  0.096924   \n2018  0.084659  0.093462  0.070972  0.122699   0.14551  0.158361  0.004916   \n2019 -0.006387 -0.015683  -0.04256 -0.073863 -0.088029 -0.076899  0.078859   \n2020  0.020553  0.005818  0.025359  0.003288 -0.028078 -0.045153 -0.070765   \n2021 -0.041456 -0.094248 -0.181759 -0.266939 -0.300769 -0.317015 -0.370859   \n\n           60        120       180       252  \n2005   0.05041 -0.252819 -0.310265 -0.206747  \n2006 -0.145031 -0.176897  -0.09253 -0.164033  \n2007   0.14894  0.455426  0.400096  0.356112  \n2008  0.323028  0.422024  0.221992   0.08494  \n2009 -0.386707 -0.178334  0.155442 -0.016063  \n2010 -0.132676 -0.056915  0.091381  0.061911  \n2011 -0.190729 -0.120154 -0.109024  0.113894  \n2012  0.070779  0.099502 -0.060434 -0.252691  \n2013 -0.061595  0.000253  0.329349  0.243597  \n2014 -0.092972 -0.210709 -0.324367 -0.368797  \n2015  0.059887 -0.063176 -0.108771 -0.485929  \n2016  0.001454  0.337634  0.185796  0.157339  \n2017   0.02553 -0.082135  0.275283  -0.12204  \n2018 -0.046683 -0.043663 -0.127068  -0.27396  \n2019  0.068867  0.075255  0.329855  0.246696  \n2020 -0.013343  0.149624 -0.057674  0.148865  \n2021 -0.331558 -0.358865 -0.549383  0.244444  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>5</th>\n      <th>10</th>\n      <th>15</th>\n      <th>20</th>\n      <th>40</th>\n      <th>60</th>\n      <th>120</th>\n      <th>180</th>\n      <th>252</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005</th>\n      <td>-0.013912</td>\n      <td>-0.033574</td>\n      <td>0.046554</td>\n      <td>0.091663</td>\n      <td>0.119357</td>\n      <td>0.095454</td>\n      <td>0.131245</td>\n      <td>0.05041</td>\n      <td>-0.252819</td>\n      <td>-0.310265</td>\n      <td>-0.206747</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>0.005942</td>\n      <td>-0.042314</td>\n      <td>-0.095925</td>\n      <td>-0.186104</td>\n      <td>-0.209612</td>\n      <td>-0.122176</td>\n      <td>-0.114209</td>\n      <td>-0.145031</td>\n      <td>-0.176897</td>\n      <td>-0.09253</td>\n      <td>-0.164033</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>-0.049753</td>\n      <td>-0.070725</td>\n      <td>-0.094438</td>\n      <td>-0.133578</td>\n      <td>-0.096542</td>\n      <td>-0.070661</td>\n      <td>0.01259</td>\n      <td>0.14894</td>\n      <td>0.455426</td>\n      <td>0.400096</td>\n      <td>0.356112</td>\n    </tr>\n    <tr>\n      <th>2008</th>\n      <td>-0.052813</td>\n      <td>-0.067155</td>\n      <td>-0.081179</td>\n      <td>-0.050072</td>\n      <td>-0.021068</td>\n      <td>-0.004175</td>\n      <td>0.175267</td>\n      <td>0.323028</td>\n      <td>0.422024</td>\n      <td>0.221992</td>\n      <td>0.08494</td>\n    </tr>\n    <tr>\n      <th>2009</th>\n      <td>-0.05369</td>\n      <td>-0.039461</td>\n      <td>-0.059318</td>\n      <td>-0.110921</td>\n      <td>-0.144375</td>\n      <td>-0.216278</td>\n      <td>-0.327895</td>\n      <td>-0.386707</td>\n      <td>-0.178334</td>\n      <td>0.155442</td>\n      <td>-0.016063</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>-0.03826</td>\n      <td>-0.031493</td>\n      <td>-0.053943</td>\n      <td>-0.071334</td>\n      <td>-0.08297</td>\n      <td>-0.111364</td>\n      <td>-0.1273</td>\n      <td>-0.132676</td>\n      <td>-0.056915</td>\n      <td>0.091381</td>\n      <td>0.061911</td>\n    </tr>\n    <tr>\n      <th>2011</th>\n      <td>0.069942</td>\n      <td>0.04667</td>\n      <td>0.016758</td>\n      <td>-0.105799</td>\n      <td>-0.173655</td>\n      <td>-0.171378</td>\n      <td>-0.245494</td>\n      <td>-0.190729</td>\n      <td>-0.120154</td>\n      <td>-0.109024</td>\n      <td>0.113894</td>\n    </tr>\n    <tr>\n      <th>2012</th>\n      <td>0.043855</td>\n      <td>0.03306</td>\n      <td>0.030747</td>\n      <td>0.067373</td>\n      <td>0.071871</td>\n      <td>0.107984</td>\n      <td>0.071357</td>\n      <td>0.070779</td>\n      <td>0.099502</td>\n      <td>-0.060434</td>\n      <td>-0.252691</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>-0.021312</td>\n      <td>-0.035287</td>\n      <td>-0.034655</td>\n      <td>-0.012332</td>\n      <td>-0.003605</td>\n      <td>0.002403</td>\n      <td>-0.014482</td>\n      <td>-0.061595</td>\n      <td>0.000253</td>\n      <td>0.329349</td>\n      <td>0.243597</td>\n    </tr>\n    <tr>\n      <th>2014</th>\n      <td>0.060462</td>\n      <td>0.06588</td>\n      <td>-0.008382</td>\n      <td>-0.019793</td>\n      <td>-0.063203</td>\n      <td>-0.09839</td>\n      <td>-0.209625</td>\n      <td>-0.092972</td>\n      <td>-0.210709</td>\n      <td>-0.324367</td>\n      <td>-0.368797</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>0.058054</td>\n      <td>0.061405</td>\n      <td>0.092519</td>\n      <td>0.108392</td>\n      <td>0.109657</td>\n      <td>0.088851</td>\n      <td>0.090875</td>\n      <td>0.059887</td>\n      <td>-0.063176</td>\n      <td>-0.108771</td>\n      <td>-0.485929</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>-0.075824</td>\n      <td>-0.101436</td>\n      <td>-0.105989</td>\n      <td>-0.183963</td>\n      <td>-0.185607</td>\n      <td>-0.19446</td>\n      <td>-0.107886</td>\n      <td>0.001454</td>\n      <td>0.337634</td>\n      <td>0.185796</td>\n      <td>0.157339</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.024382</td>\n      <td>0.035729</td>\n      <td>0.101195</td>\n      <td>0.074486</td>\n      <td>0.117578</td>\n      <td>0.103618</td>\n      <td>0.096924</td>\n      <td>0.02553</td>\n      <td>-0.082135</td>\n      <td>0.275283</td>\n      <td>-0.12204</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.084659</td>\n      <td>0.093462</td>\n      <td>0.070972</td>\n      <td>0.122699</td>\n      <td>0.14551</td>\n      <td>0.158361</td>\n      <td>0.004916</td>\n      <td>-0.046683</td>\n      <td>-0.043663</td>\n      <td>-0.127068</td>\n      <td>-0.27396</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>-0.006387</td>\n      <td>-0.015683</td>\n      <td>-0.04256</td>\n      <td>-0.073863</td>\n      <td>-0.088029</td>\n      <td>-0.076899</td>\n      <td>0.078859</td>\n      <td>0.068867</td>\n      <td>0.075255</td>\n      <td>0.329855</td>\n      <td>0.246696</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>0.020553</td>\n      <td>0.005818</td>\n      <td>0.025359</td>\n      <td>0.003288</td>\n      <td>-0.028078</td>\n      <td>-0.045153</td>\n      <td>-0.070765</td>\n      <td>-0.013343</td>\n      <td>0.149624</td>\n      <td>-0.057674</td>\n      <td>0.148865</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>-0.041456</td>\n      <td>-0.094248</td>\n      <td>-0.181759</td>\n      <td>-0.266939</td>\n      <td>-0.300769</td>\n      <td>-0.317015</td>\n      <td>-0.370859</td>\n      <td>-0.331558</td>\n      <td>-0.358865</td>\n      <td>-0.549383</td>\n      <td>0.244444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAU_RESULTS[\"delta interest\"][\"call\"][\"baseline\"][\"coef\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ----------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Splitting Data Into Training and Testing**\n",
    "\n",
    "We split our call and put data into 80% training and 20% testing. No shuffling because data is time-series (order dependent)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "all_dates = np.sort(calls_df[\"date\"].unique())\n",
    "\n",
    "dates_train, dates_test = train_test_split(all_dates, test_size=0.2, random_state=None, shuffle=False)\n",
    "\n",
    "adj_closing_train = adj_closing_df[adj_closing_df[\"date\"].isin(dates_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kendall rank correlations for each type of slope / intercept coefficient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "input_list = []\n",
    "lr_cols = list(LR_fits.columns)\n",
    "lr_cols.remove(\"date\")\n",
    "lr_cols.remove(\"option type\")\n",
    "delta_cols = list(Y_TRAIN_STAT.columns)\n",
    "delta_cols.remove(\"date\")\n",
    "\n",
    "for option_type in [\"call\", \"put\"]:\n",
    "    for col1 in lr_cols:\n",
    "        temp_lr = LR_fits[LR_fits[\"option type\"] == option_type][[\"date\", col1]]\n",
    "        for col2 in delta_cols:\n",
    "            temp_delta = Y_TRAIN_STAT[[\"date\", col2]].dropna()\n",
    "            temp_joined = temp_lr.merge(temp_delta, how=\"inner\", on=\"date\")\n",
    "            temp_joined.drop(columns=\"date\", inplace=True)\n",
    "            input_list.append([temp_joined, option_type])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "my_pool = Pool(multiprocessing.cpu_count())\n",
    "\n",
    "results = my_pool.map(kendall_rank, input_list)\n",
    "\n",
    "# Make sure column names correspond to the order returned by the function\n",
    "RESULTS_DF = pd.DataFrame(data=results, columns=[\"tau\", \"pval\", \"id1\", \"id2\", \"option type\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Violin plot to visualize the efficacy of different metrics (probs delete)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tau_violin = go.Figure()\n",
    "\n",
    "tau_violin.add_trace(go.Violin(x=RESULTS_DF[\"id1\"][RESULTS_DF[\"option type\"] == \"call\"],\n",
    "                               y=RESULTS_DF[\"tau\"][RESULTS_DF[\"option type\"] == \"call\"],\n",
    "                               name=\"call\",\n",
    "                               side=\"positive\", line={\"color\": \"orange\"}))\n",
    "\n",
    "tau_violin.add_trace(go.Violin(x=RESULTS_DF[\"id1\"][RESULTS_DF[\"option type\"] == \"put\"],\n",
    "                               y=RESULTS_DF[\"tau\"][RESULTS_DF[\"option type\"] == \"put\"],\n",
    "                               name=\"put\",\n",
    "                               side=\"negative\", line={\"color\": \"blue\"}))\n",
    "\n",
    "tau_violin.update_traces(meanline_visible=True)\n",
    "tau_violin.update_layout(violinmode='overlay',\n",
    "                         title=\"Kendall Tau Correlation Distributions of Various Metrics\",\n",
    "                         yaxis_title=\"Kendall Tau Correlation\",\n",
    "                         font={\"size\": 14})\n",
    "\n",
    "tau_violin.show(renderer=\"browser\")\n",
    "\n",
    "tau_violin.write_image(\"./img/EDA2_tau_violin.svg\", width=1200, height=800)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![violin](../img/EDA2_tau_violin.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line plot to visualize the effects of increasing lag on correlation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "tau_scatter = make_subplots(rows=1, cols=2, shared_yaxes=True,\n",
    "                            subplot_titles=(\"Call\", \"Put\"))\n",
    "\n",
    "for option_type in [\"call\", \"put\"]:\n",
    "    for metric in np.unique(RESULTS_DF[\"id1\"]):\n",
    "        if option_type == \"call\":\n",
    "            ncol = 1\n",
    "        else:\n",
    "            ncol = 2\n",
    "\n",
    "        tau_scatter.add_trace(\n",
    "            go.Scatter(x=RESULTS_DF[(RESULTS_DF[\"option type\"] == option_type) & (RESULTS_DF[\"id1\"] == metric)][\"id2\"],\n",
    "                       y=RESULTS_DF[(RESULTS_DF[\"option type\"] == option_type) & (RESULTS_DF[\"id1\"] == metric)][\"tau\"],\n",
    "                       name=f\"{option_type}_{metric}\", mode=\"lines+markers\"),\n",
    "            row=1, col=ncol)\n",
    "\n",
    "tau_scatter.update_layout(title=\"Kendall Tau Correlation vs. Lag of Various Metrics\",\n",
    "                          yaxis_title=\"Kendall Tau Correlation\",\n",
    "                          font={\"size\": 14})\n",
    "\n",
    "tau_scatter.show(renderer=\"browser\")\n",
    "\n",
    "tau_scatter.write_image(\"./img/EDA2_tau_scatter.svg\", width=1600, height=800)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![scatter](../img/EDA2_tau_scatter.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above, we see that features `baseline_i`, call `sign_i`, and put `baseline_s` have the best performance. Most features on the put side have an average tau of ~0.05.\n",
    "\n",
    "We also notice that, aside from call `baseline_i`, the 3 other \"significant\" features get better the further out we are trying to predict. This is counter-intuitive, because we expect the predictive ability of data to decay the further out we go.\n",
    "\n",
    "A possible explanation for the poor performance of metrics derived from engineered features (e.g. linear regression weighted by `|change in open contracts|`, or the more complicated `|change in open contracts * ask/bid price|`) could be due to the systematic irregularities of how options are traded. Here are some possible explanations:\n",
    "- Some options are bought to \"lock in\" gains in an investor's portfolio. For example, if an investor who recently invested in stock `ABC` wants to cash out, but also wants to avoid the short term capital gains tax. He/she can achieve this by selling call options or buying put options. These movements are usually large (since they want to cover all of their holdings), and are not reflective of the short term \"sentiment\" of stock `ABC`.\n",
    "- By taking a look at the net change in open interest on various days, I noticed that the values are usually inflated shortly before ex-dividend dates.\n",
    "    - For stock `CVX` (Chevron Corporation), there were spikes on 04-28, 05-16, 08-16 and 11-15 in 2016. The ex-dividend dates were 02-16, 05-17, 08-17 and 11-16. This happens with stocks that are dividend heavy, as in the case with `CVX`.\n",
    "    - This could be because investors want to cash out on the dividends, other quant firms trade dividend events ...etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manual selection of model based on Kendall Tau"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualization of selected model\n",
    "model_option_type = \"put\"\n",
    "model_metric = \"baseline_i\"\n",
    "model_lag = \"delta 33\"\n",
    "\n",
    "MODEL_DF = LR_fits[[\"date\", model_metric]][LR_fits[\"option type\"] == model_option_type]\n",
    "\n",
    "MODEL_DF = MODEL_DF.merge(Y_TRAIN_STAT[[\"date\", model_lag]].dropna(),\n",
    "                          on=\"date\", how=\"inner\")\n",
    "\n",
    "model_scatter_plot = px.scatter(MODEL_DF, x=model_metric, y=model_lag,\n",
    "                                marginal_x=\"violin\",\n",
    "                                marginal_y=\"violin\")\n",
    "\n",
    "model_scatter_plot.update_layout(\n",
    "    title=f\"{model_lag} vs. {model_option_type}_{model_metric}\",\n",
    "    xaxis_title=f\"{model_option_type}_{model_metric}\",\n",
    "    yaxis_title=f\"{model_lag}\",\n",
    "    font={\"size\": 16}\n",
    ")\n",
    "\n",
    "model_scatter_plot.show(renderer=\"browser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method to calculate probability distribution of dependent variable given an independent observation\n",
    "\n",
    "From the scatter plot, we see that neither the dependent nor independent variables have easy parametric characterizations. It would be hard to fit a well-defined probability distribution on it (e.g. bivariate normal distribution).\n",
    "\n",
    "Instead, I will apply the following to help \"parameterize\" the data:\n",
    "1. Center data\n",
    "2. Detrend the points using linear regression\n",
    "3. Divide both the dependent and independent residuals by their marginal standard deviations\n",
    "\n",
    "After removing all the \"parametric\" descriptors, we use multivariate kernel density (KDE) estimation to characterize the residuals non-parametrically.\n",
    "- Gaussian kernel using euclidean distance.\n",
    "- Scott and Silverman rules to find ideal bandwidths for our KDE. We can compare this to built-in cross validation methods.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "MODEL_PROB_DF = MODEL_DF.copy()\n",
    "\n",
    "# Center data\n",
    "CENTROID = np.array([np.mean(MODEL_PROB_DF[model_metric]), np.mean(MODEL_PROB_DF[model_lag])])\n",
    "MODEL_PROB_DF[f\"{model_metric}_c\"] = MODEL_PROB_DF[model_metric] - CENTROID[0]\n",
    "MODEL_PROB_DF[f\"{model_lag}_c\"] = MODEL_PROB_DF[model_lag] - CENTROID[1]\n",
    "\n",
    "# Detrend using linear regression\n",
    "MODEL_SCATTER = linear_model.LinearRegression(fit_intercept=False).fit(X=MODEL_PROB_DF[[f\"{model_metric}\"]],\n",
    "                                                                       y=MODEL_PROB_DF[[f\"{model_lag}\"]])\n",
    "\n",
    "MODEL_PROB_DF[f\"{model_lag}_c_detrend\"] = (MODEL_PROB_DF[f\"{model_lag}_c\"] -\n",
    "                                           (float(MODEL_SCATTER.coef_) * MODEL_PROB_DF[f\"{model_metric}_c\"]))\n",
    "\n",
    "# Normalize residuals using marginal standard deviations\n",
    "Y_SD = np.std(MODEL_PROB_DF[f\"{model_lag}_c_detrend\"])\n",
    "X_SD = np.std(MODEL_PROB_DF[f\"{model_metric}_c\"])\n",
    "\n",
    "MODEL_PROB_DF[f\"{model_lag}_c_detrend_norm\"] = MODEL_PROB_DF[f\"{model_lag}_c_detrend\"] / Y_SD\n",
    "MODEL_PROB_DF[f\"{model_metric}_c_norm\"] = MODEL_PROB_DF[f\"{model_metric}_c\"] / X_SD\n",
    "\n",
    "# Remove later\n",
    "margin_plot = px.scatter(MODEL_PROB_DF, x=f\"{model_metric}_c_norm\", y=f\"{model_lag}_c_detrend_norm\",\n",
    "                         marginal_x=\"violin\",\n",
    "                         marginal_y=\"violin\")\n",
    "\n",
    "margin_plot.show(renderer=\"browser\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting kernel density\n",
    "\n",
    "In the case of 2 dimensional data here, Scott and Silverman bandwidth are the same."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# KDE using Scott / Silverman\n",
    "ss_bw = [200 ** (-1 / 6), 200 ** (-1 / 6)]\n",
    "\n",
    "SS_KDE = KDEMultivariate(data=MODEL_PROB_DF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]],\n",
    "                         var_type=\"cc\", bw=ss_bw)\n",
    "\n",
    "# Cross validation max likelihood\n",
    "\n",
    "CVML_KDE = KDEMultivariate(data=MODEL_PROB_DF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]],\n",
    "                           var_type=\"cc\", bw=\"cv_ml\")\n",
    "\n",
    "# Cross validation least squares\n",
    "\n",
    "CVLS_KDE = KDEMultivariate(data=MODEL_PROB_DF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]],\n",
    "                           var_type=\"cc\", bw=\"cv_ls\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given a new observed value of `x`, we can generate a marginal distribution along `y`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "observed_x = -1\n",
    "step_size = 0.1\n",
    "y_range = np.arange(-3, 3 + step_size, step_size)\n",
    "\n",
    "temp_list = []\n",
    "for n in y_range:\n",
    "    temp_list.append([observed_x, n])\n",
    "\n",
    "PREDICTION_PDF = pd.DataFrame(data=temp_list, columns=[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"])\n",
    "\n",
    "# Create predictions\n",
    "PREDICTION_PDF[\"SS\"] = SS_KDE.pdf(PREDICTION_PDF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]])\n",
    "PREDICTION_PDF[\"CVML\"] = CVML_KDE.pdf(PREDICTION_PDF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]])\n",
    "PREDICTION_PDF[\"CVLS\"] = CVLS_KDE.pdf(PREDICTION_PDF[[f\"{model_metric}_c_norm\", f\"{model_lag}_c_detrend_norm\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Standardizing the PDF such that the area under is approx. 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for my_type in [\"SS\", \"CVML\", \"CVLS\"]:\n",
    "    fig.add_trace(go.Scatter(x=PREDICTION_PDF[f\"{model_lag}_c_detrend_norm\"],\n",
    "                             y=PREDICTION_PDF[my_type],\n",
    "                             mode='lines+markers', name=my_type))\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}