{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering (Continued from `EDA_1`)\n",
    "**Import required packages & check working directory**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import graph_fun\n",
    "from model_fun import kendall_rank\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "if os.getcwd()[-3:] == \"src\":\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**User defined parameters**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ticker = \"CVX\"\n",
    "stock_data_path = \"data/EDA/\"\n",
    "adj_daily_closing_path = \"data/adjusted_daily_closing/\"\n",
    "adj_daily_dividend_path = \"data/dividends/\"\n",
    "eda_data_path = \"data/EDA/\"\n",
    "# lead_days = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load adjusted daily closing and dividends**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "daily_closing = pd.read_csv(os.path.abspath(os.path.join(adj_daily_closing_path, (ticker + \".csv\"))))\n",
    "daily_closing[\"date\"] = pd.to_datetime(daily_closing[\"date\"]).dt.date\n",
    "\n",
    "daily_dividend = pd.read_csv(os.path.abspath(os.path.join(adj_daily_dividend_path, (ticker + \"_ts.csv\"))))\n",
    "daily_dividend[\"date\"] = pd.to_datetime(daily_dividend[\"date\"]).dt.date\n",
    "\n",
    "adj_closing_df = daily_closing[[\"date\", \"close\"]].merge(right=daily_dividend,\n",
    "                                                        how=\"inner\",\n",
    "                                                        on=\"date\")\n",
    "\n",
    "adj_closing_df[\"adj closing\"] = (adj_closing_df[\"close\"] - adj_closing_df[\"amount\"]).round(6)\n",
    "adj_closing_df = adj_closing_df[[\"date\", \"adj closing\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load data from `EDA_1.ipynb`**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "calls_df = pd.DataFrame()\n",
    "puts_df = pd.DataFrame()\n",
    "\n",
    "for n in [\"calls\", \"puts\"]:\n",
    "    my_df = pd.read_csv(os.path.abspath(os.path.join(eda_data_path, (ticker + f\"_{n}_EDA1.csv\"))))\n",
    "    my_df[\"date\"] = pd.to_datetime(my_df[\"date\"]).dt.date\n",
    "    my_df[\"expiration date\"] = pd.to_datetime(my_df[\"expiration date\"]).dt.date\n",
    "    if n == \"calls\":\n",
    "        calls_df = my_df\n",
    "    elif n == \"puts\":\n",
    "        puts_df = my_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Splitting Data Into Training and Testing**\n",
    "\n",
    "We split our call and put data into 80% training and 20% testing. No shuffling because data is time-series (order dependent)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "all_dates = np.sort(calls_df[\"date\"].unique())\n",
    "\n",
    "dates_train, dates_test = train_test_split(all_dates, test_size=0.2, random_state=None, shuffle=False)\n",
    "\n",
    "adj_closing_train = adj_closing_df[adj_closing_df[\"date\"].isin(dates_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a Dickey-Fuller test to see if a unit root is present in end-of-day prices."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.315451\n",
      "p-value: 0.622074\n",
      "Critical Values:\n",
      "\t1%: -3.464\n",
      "\t5%: -2.876\n",
      "\t10%: -2.575\n"
     ]
    }
   ],
   "source": [
    "adfuller_og = adfuller(adj_closing_train[\"adj closing\"], regression=\"c\", autolag=\"AIC\")\n",
    "\n",
    "print('ADF Statistic: %f' % adfuller_og[0])\n",
    "print('p-value: %f' % adfuller_og[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adfuller_og[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A p=value of 0.622 indicates we cannot reject the null hypothesis of a unit root being present.\n",
    "\n",
    "Plotting time series, autocorrelation (ACF) and partial ACF to pick appropriate de-trending options."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "acf_plot = graph_fun.ts_decompose(ts=adj_closing_train[\"adj closing\"], nlags=30,\n",
    "                                  dates=adj_closing_train[\"date\"])\n",
    "\n",
    "acf_plot.show(renderer=\"browser\")\n",
    "\n",
    "acf_plot.write_image(\"./img/EDA2_ACF.svg\", width=750, height=800)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the appropriate ARIMA model for this time series. It seems that the model would benefit the most from differencing of 1 (d = 1). There does not seem to be a clear seasonality to the data (perhaps b.c. we only have 1 year of data?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Take the difference between neighbouring observations\n",
    "Y_TRAIN_STAT = adj_closing_train.reset_index(drop=True).copy()\n",
    "\n",
    "for delta in range(1, 21):\n",
    "    Y_TRAIN_STAT[f\"delta {delta}\"] = (Y_TRAIN_STAT[\"adj closing\"] - (adj_closing_train[\"adj closing\"]\n",
    "                                                                     .shift(periods=delta)\n",
    "                                                                     .reset_index(drop=True)))\n",
    "\n",
    "Y_TRAIN_STAT.drop(columns=[\"adj closing\"], inplace=True)\n",
    "\n",
    "# Show ACF of delta = 1 residuals\n",
    "delta = 1\n",
    "acf_plot_l1 = graph_fun.ts_decompose(ts=Y_TRAIN_STAT[f\"delta {delta}\"].dropna(), nlags=30,\n",
    "                                     dates=Y_TRAIN_STAT[\"date\"][delta:],\n",
    "                                     y_label=f\"Delta {delta} Adj. Closing\")\n",
    "\n",
    "acf_plot_l1.show(renderer=\"browser\")\n",
    "\n",
    "acf_plot_l1.write_image(\"./img/EDA2_ACF2.pdf\", width=750, height=800)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ACF](../img/EDA2_ACF2.pdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using Dickey-Fuller test to examine stationarity at different lags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     delta 1  delta 2  delta 5  delta 10  delta 15  delta 20\n",
      "ADF Stat.          -17.17277 -4.82437 -3.40888  -3.87423  -3.40522  -3.22498\n",
      "p-value              0.00000  0.00005  0.01066   0.00223   0.01078   0.01858\n",
      "critical value 1%   -3.46382 -3.46601 -3.46742  -3.46742  -3.46660  -3.46763\n",
      "critical value 5%   -2.87625 -2.87721 -2.87783  -2.87783  -2.87747  -2.87792\n",
      "critical value 10%  -2.57461 -2.57512 -2.57545  -2.57545  -2.57526  -2.57550\n"
     ]
    }
   ],
   "source": [
    "adfuller_df = pd.DataFrame(index=[\"ADF Stat.\", \"p-value\",\n",
    "                                  \"critical value 1%\", \"critical value 5%\", \"critical value 10%\"])\n",
    "\n",
    "for delta in [1, 2, 5, 10, 15, 20]:\n",
    "    temp_adfuller = adfuller(Y_TRAIN_STAT[f\"delta {delta}\"].dropna(), regression=\"c\", autolag=\"AIC\")\n",
    "\n",
    "    adfuller_df[f\"delta {delta}\"] = [round(temp_adfuller[0], 5),\n",
    "                                     round(temp_adfuller[1], 5),\n",
    "                                     round(temp_adfuller[4][\"1%\"], 5),\n",
    "                                     round(temp_adfuller[4][\"5%\"], 5),\n",
    "                                     round(temp_adfuller[4][\"10%\"], 5)]\n",
    "\n",
    "print(adfuller_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By taking the daily change (I = 1) in end of day prices, the dependent variable becomes stationary.\n",
    "\n",
    "With more data, we can try to find a seasonal ARMA model that fits the residuals.\n",
    "\n",
    "As the delta increases between adjusted EOD prices, the p-value increases as well. However, the residual is still considered stationary.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Creating features to help draw relationships between option data and residuals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "CALL_FEATS = pd.DataFrame()\n",
    "PUT_FEATS = pd.DataFrame()\n",
    "\n",
    "for df in [[calls_df, 1], [puts_df, 2]]:\n",
    "    temp_df = df[0].copy()\n",
    "    temp_df = temp_df[temp_df[\"date\"].isin(dates_train)]\n",
    "    temp_df = temp_df[temp_df[\"delta interest\"] != 0].reset_index(drop=True)\n",
    "    temp_df[\"ask er\"] = temp_df[\"ask price\"] * temp_df[\"delta interest\"]\n",
    "    temp_df[\"bid er\"] = temp_df[\"bid price\"] * temp_df[\"delta interest\"]\n",
    "\n",
    "    if df[1] == 1:\n",
    "        temp_df[\"moneyness\"] = temp_df[\"adj closing\"] - temp_df[\"adj strike\"]\n",
    "    else:\n",
    "        temp_df[\"moneyness\"] = temp_df[\"adj strike\"] - temp_df[\"adj closing\"]\n",
    "\n",
    "    temp_df[\"sign\"] = np.sign(temp_df[\"delta interest\"])\n",
    "\n",
    "    temp_df = temp_df[[\"date\", \"days till exp\", \"delta interest\", \"sign\",\n",
    "                       \"moneyness\", \"ask er\", \"bid er\"]]\n",
    "\n",
    "    if df[1] == 1:\n",
    "        CALL_FEATS = temp_df\n",
    "    else:\n",
    "        PUT_FEATS = temp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting linear regression using different features\n",
    "1. Baseline linear regression between days until option expiry and moneyness\n",
    "2. Above + takes into account whether the total number of open contracts increased or decreased\n",
    "3. `2` + weighted by absolute change in open contracts\n",
    "4. `2` + weighted by \"ask er\" as defined above\n",
    "5. `2` + weighted by \"bid er\" as defined above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "LR_fits = []\n",
    "\n",
    "for date in dates_train:\n",
    "    for my_input in [[CALL_FEATS, \"call\"], [PUT_FEATS, \"put\"]]:\n",
    "        temp_df = (my_input[0])[(my_input[0])[\"date\"] == date]\n",
    "\n",
    "        lr_base = linear_model.LinearRegression().fit(X=temp_df[[\"days till exp\"]],\n",
    "                                                      y=temp_df[\"moneyness\"])\n",
    "\n",
    "        lr_sign = linear_model.LinearRegression().fit(X=temp_df[[\"days till exp\"]],\n",
    "                                                      y=temp_df[\"moneyness\"] * temp_df[\"sign\"])\n",
    "\n",
    "        lr_delta = linear_model.LinearRegression().fit(X=temp_df[[\"days till exp\"]],\n",
    "                                                       y=temp_df[\"moneyness\"] * temp_df[\"sign\"],\n",
    "                                                       sample_weight=np.abs(\n",
    "                                                           temp_df[\"delta interest\"]))\n",
    "\n",
    "        lr_er_ask = linear_model.LinearRegression().fit(X=temp_df[[\"days till exp\"]],\n",
    "                                                        y=temp_df[\"moneyness\"] * temp_df[\"sign\"],\n",
    "                                                        sample_weight=np.abs(\n",
    "                                                            temp_df[\"ask er\"]))\n",
    "\n",
    "        lr_er_bid = linear_model.LinearRegression().fit(X=temp_df[[\"days till exp\"]],\n",
    "                                                        y=temp_df[\"moneyness\"] * temp_df[\"sign\"],\n",
    "                                                        sample_weight=np.abs(\n",
    "                                                            temp_df[\"bid er\"]))\n",
    "\n",
    "        temp_fits = [date,\n",
    "                     lr_base.coef_[0], lr_base.intercept_,\n",
    "                     lr_sign.coef_[0], lr_sign.intercept_,\n",
    "                     lr_delta.coef_[0], lr_delta.intercept_,\n",
    "                     lr_er_ask.coef_[0], lr_er_ask.intercept_,\n",
    "                     lr_er_bid.coef_[0], lr_er_bid.intercept_]\n",
    "\n",
    "        if my_input[1] == \"call\":\n",
    "            temp_fits.append(\"call\")\n",
    "            LR_fits.append(temp_fits)\n",
    "        else:\n",
    "            temp_fits.append(\"put\")\n",
    "            LR_fits.append(temp_fits)\n",
    "\n",
    "LR_fits = pd.DataFrame(LR_fits, columns=[\"date\",\n",
    "                                         \"baseline_s\", \"baseline_i\",\n",
    "                                         \"sign_s\", \"sign_i\",\n",
    "                                         \"weighted_delta_s\", \"weighted_delta_i\",\n",
    "                                         \"weighted_ask_er_s\", \"weighted_ask_er_i\",\n",
    "                                         \"weighted_bid_er_s\", \"weighted_bid_er_i\",\n",
    "                                         \"option type\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         date  baseline_s  baseline_i    sign_s    sign_i  weighted_delta_s  \\\n0  2016-01-04   -0.015845   -3.106311 -0.023524  0.972470         -0.039414   \n1  2016-01-04   -0.010023   -4.303141 -0.008660 -3.167798         -0.036403   \n2  2016-01-05   -0.011184   -2.410562  0.002616 -1.060309          0.004163   \n3  2016-01-05    0.010021   -4.839111  0.009236 -3.776612         -0.076194   \n4  2016-01-06   -0.009840   -3.651803 -0.007106  0.899670         -0.011108   \n\n   weighted_delta_i  weighted_ask_er_s  weighted_ask_er_i  weighted_bid_er_s  \\\n0         -2.574678          -0.019102          -3.563837          -0.018223   \n1         -0.819443           0.010782          -2.786647           0.012764   \n2         -2.797290           0.018259          -0.835753           0.018324   \n3          6.170687          -0.061745          10.858818          -0.062534   \n4         -1.816048           0.015329          -2.094608           0.015464   \n\n   weighted_bid_er_i option type  \n0          -3.605539        call  \n1          -2.964281         put  \n2          -0.718303        call  \n3          10.882176         put  \n4          -2.102186        call  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>baseline_s</th>\n      <th>baseline_i</th>\n      <th>sign_s</th>\n      <th>sign_i</th>\n      <th>weighted_delta_s</th>\n      <th>weighted_delta_i</th>\n      <th>weighted_ask_er_s</th>\n      <th>weighted_ask_er_i</th>\n      <th>weighted_bid_er_s</th>\n      <th>weighted_bid_er_i</th>\n      <th>option type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-04</td>\n      <td>-0.015845</td>\n      <td>-3.106311</td>\n      <td>-0.023524</td>\n      <td>0.972470</td>\n      <td>-0.039414</td>\n      <td>-2.574678</td>\n      <td>-0.019102</td>\n      <td>-3.563837</td>\n      <td>-0.018223</td>\n      <td>-3.605539</td>\n      <td>call</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-04</td>\n      <td>-0.010023</td>\n      <td>-4.303141</td>\n      <td>-0.008660</td>\n      <td>-3.167798</td>\n      <td>-0.036403</td>\n      <td>-0.819443</td>\n      <td>0.010782</td>\n      <td>-2.786647</td>\n      <td>0.012764</td>\n      <td>-2.964281</td>\n      <td>put</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-05</td>\n      <td>-0.011184</td>\n      <td>-2.410562</td>\n      <td>0.002616</td>\n      <td>-1.060309</td>\n      <td>0.004163</td>\n      <td>-2.797290</td>\n      <td>0.018259</td>\n      <td>-0.835753</td>\n      <td>0.018324</td>\n      <td>-0.718303</td>\n      <td>call</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-05</td>\n      <td>0.010021</td>\n      <td>-4.839111</td>\n      <td>0.009236</td>\n      <td>-3.776612</td>\n      <td>-0.076194</td>\n      <td>6.170687</td>\n      <td>-0.061745</td>\n      <td>10.858818</td>\n      <td>-0.062534</td>\n      <td>10.882176</td>\n      <td>put</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-06</td>\n      <td>-0.009840</td>\n      <td>-3.651803</td>\n      <td>-0.007106</td>\n      <td>0.899670</td>\n      <td>-0.011108</td>\n      <td>-1.816048</td>\n      <td>0.015329</td>\n      <td>-2.094608</td>\n      <td>0.015464</td>\n      <td>-2.102186</td>\n      <td>call</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_fits.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kendall rank correlations for each type of slope / intercept coefficient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "input_list = []\n",
    "lr_cols = list(LR_fits.columns)\n",
    "lr_cols.remove(\"date\")\n",
    "lr_cols.remove(\"option type\")\n",
    "delta_cols = list(Y_TRAIN_STAT.columns)\n",
    "delta_cols.remove(\"date\")\n",
    "\n",
    "for option_type in [\"call\", \"put\"]:\n",
    "    for col1 in lr_cols:\n",
    "        temp_lr = LR_fits[LR_fits[\"option type\"] == option_type][[\"date\", col1]]\n",
    "        for col2 in delta_cols:\n",
    "            temp_delta = Y_TRAIN_STAT[[\"date\", col2]].dropna()\n",
    "            temp_joined = temp_lr.merge(temp_delta, how=\"inner\", on=\"date\")\n",
    "            temp_joined.drop(columns=\"date\", inplace=True)\n",
    "            input_list.append([temp_joined, option_type])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "my_pool = Pool(multiprocessing.cpu_count())\n",
    "\n",
    "results = my_pool.map(kendall_rank, input_list)\n",
    "\n",
    "# Make sure column names correspond to the order returned by the function\n",
    "RESULTS_DF = pd.DataFrame(data=results, columns=[\"tau\", \"pval\", \"id1\", \"id2\", \"option type\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Violin plot to visualize the efficacy of different metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tau_violin = go.Figure()\n",
    "\n",
    "tau_violin.add_trace(go.Violin(x=RESULTS_DF[\"id1\"][RESULTS_DF[\"option type\"] == \"call\"],\n",
    "                               y=RESULTS_DF[\"tau\"][RESULTS_DF[\"option type\"] == \"call\"],\n",
    "                               name=\"call\",\n",
    "                               side=\"positive\", line={\"color\": \"orange\"}))\n",
    "\n",
    "tau_violin.add_trace(go.Violin(x=RESULTS_DF[\"id1\"][RESULTS_DF[\"option type\"] == \"put\"],\n",
    "                               y=RESULTS_DF[\"tau\"][RESULTS_DF[\"option type\"] == \"put\"],\n",
    "                               name=\"put\",\n",
    "                               side=\"negative\", line={\"color\": \"blue\"}))\n",
    "\n",
    "tau_violin.update_traces(meanline_visible=True)\n",
    "tau_violin.update_layout(violingap=0.1, violinmode='overlay',\n",
    "                         title=\"Kendall Tau Correlation Distributions of Various Metrics\",\n",
    "                         yaxis_title=\"Kendall Tau Correlation\",\n",
    "                         font={\"size\": 14})\n",
    "\n",
    "tau_violin.show(renderer=\"browser\")\n",
    "\n",
    "tau_violin.write_image(\"./img/EDA2_tau_violin.pdf\", width=1200, height=800)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![violin](../img/EDA2_tau_violin.pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line plot to visualize the effects of increasing lag on correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tau_scatter = make_subplots(rows=1, cols=2, shared_yaxes=True,\n",
    "                            subplot_titles=(\"Call\", \"Put\"))\n",
    "\n",
    "for option_type in [\"call\", \"put\"]:\n",
    "    for metric in np.unique(RESULTS_DF[\"id1\"]):\n",
    "        if option_type == \"call\":\n",
    "            ncol = 1\n",
    "        else:\n",
    "            ncol = 2\n",
    "        tau_scatter.add_trace(\n",
    "            go.Scatter(x=RESULTS_DF[(RESULTS_DF[\"option type\"] == option_type) & (RESULTS_DF[\"id1\"] == metric)][\"id2\"],\n",
    "                       y=RESULTS_DF[(RESULTS_DF[\"option type\"] == option_type) & (RESULTS_DF[\"id1\"] == metric)][\"tau\"],\n",
    "                       name=metric, mode=\"lines+markers\"),\n",
    "            row=1, col=ncol)\n",
    "\n",
    "\n",
    "tau_scatter.update_layout(title=\"Kendall Tau Correlation vs. Lag of Various Metrics\",\n",
    "                          yaxis_title=\"Kendall Tau Correlation\",\n",
    "                          font={\"size\": 14})\n",
    "\n",
    "tau_scatter.show(renderer=\"browser\")\n",
    "\n",
    "tau_scatter.write_image(\"./img/EDA2_tau_scatter.pdf\", width=1600, height=800)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![scatter](../img/EDA2_tau_scatter.pdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above, we see that features `baseline_i`, call `sign_i`, and put `baseline_s` have the best performance. Most features on the put side have an average tau of ~0.05.\n",
    "\n",
    "We also notice that, aside from call `baseline_i`, the 3 other \"significant\" features get better the further out we are trying to predict. This is counter-intuitive, because we expect the predictive ability of data to decay the further out we go.\n",
    "\n",
    "A possible explanation for the poor performance of metrics derived from engineered features (e.g. linear regression weighted by `|change in open contracts|`, or the more complicated `|change in open contracts * ask/bid price|`) could be due to the systematic irregularities of how options are traded. Here are some possible explanations:\n",
    "- Some options are bought to \"lock in\" gains in an investor's portfolio. For example, if an investor who recently invested in stock `ABC` wants to cash out, but also wants to avoid the short term capital gains tax. He/she can achieve this by selling call options or buying put options. These movements are usually large (since they want to cover all of their holdings), and are not reflective of the short term \"sentiment\" of stock `ABC`.\n",
    "- By taking a look at the net change in open interest on various days, I noticed that the values are usually inflated shortly before ex-dividend dates.\n",
    "    - For stock `CVX` (Chevron Corporation), there were spikes on 04-28, 05-16, 08-16 and 11-15 in 2016. The ex-dividend dates were 02-16, 05-17, 08-17 and 11-16. This happens with stocks that are dividend heavy, as in the case with `CVX`.\n",
    "    - This could be because investors want to cash out on the dividends, other quant firms trade dividend events ...etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}